{"docstore/metadata": {"fa430390-4487-4085-a675-14995febf3c7": {"doc_hash": "3d5190f8dcdf7c69973635ab8f0b9b75ccc7f8d5a5d7405f749b90d990c89c12"}, "0c130d6f-f335-4975-9d7e-52cf80248652": {"doc_hash": "3629a74a9a02a4c7c9153948f0a275c69a033c078b191e47ce84d3271f0749f4", "ref_doc_id": "fa430390-4487-4085-a675-14995febf3c7"}}, "docstore/ref_doc_info": {"fa430390-4487-4085-a675-14995febf3c7": {"node_ids": ["0c130d6f-f335-4975-9d7e-52cf80248652"], "metadata": {"file_path": "C:\\Users\\Abhishek.k\\Music\\Python\\data\\Main.py", "file_name": "Main.py", "file_type": "text/x-python", "file_size": 1090, "creation_date": "2025-07-18", "last_modified_date": "2025-07-18"}}}, "docstore/data": {"0c130d6f-f335-4975-9d7e-52cf80248652": {"__data__": {"id_": "0c130d6f-f335-4975-9d7e-52cf80248652", "embedding": null, "metadata": {"file_path": "C:\\Users\\Abhishek.k\\Music\\Python\\data\\Main.py", "file_name": "Main.py", "file_type": "text/x-python", "file_size": 1090, "creation_date": "2025-07-18", "last_modified_date": "2025-07-18"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fa430390-4487-4085-a675-14995febf3c7", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Abhishek.k\\Music\\Python\\data\\Main.py", "file_name": "Main.py", "file_type": "text/x-python", "file_size": 1090, "creation_date": "2025-07-18", "last_modified_date": "2025-07-18"}, "hash": "3d5190f8dcdf7c69973635ab8f0b9b75ccc7f8d5a5d7405f749b90d990c89c12", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage\r\nfrom llama_index.embeddings.langchain import LangchainEmbedding\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\nfrom llama_index.core import Settings\r\n\r\n# \u2705 Set local embedding model\r\nlocal_embed_model = LangchainEmbedding(\r\n    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\r\n)\r\nSettings.embed_model = local_embed_model\r\n\r\n# \u2705 Disable LLM completely (so it doesn't call OpenAI)\r\nSettings.llm = None\r\n\r\n# \u2705 Load documents\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\n\r\n# \u2705 Build index\r\nindex = VectorStoreIndex.from_documents(documents)\r\n\r\n# \u2705 Persist index\r\nindex.storage_context.persist(persist_dir='index_store')\r\n\r\n# \u2705 Reload index later\r\nstorage_context = StorageContext.from_defaults(persist_dir='index_store')\r\nloaded_index = load_index_from_storage(storage_context)\r\n\r\n# \u2705 Query engine (no LLM involved)\r\nquery_engine = loaded_index.as_query_engine()\r\nresponse = query_engine.query(\"What is this chatbot about?\")\r\nprint(response)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1074, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}